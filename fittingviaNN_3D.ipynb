{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"N2H2_VVdata_3variables.xlsx\"\n",
    "df = pd.read_excel(filename)\n",
    "debug = False\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x = df[['v', 'w', 'T(K)']].values\n",
    "#use logscakle \n",
    "y = np.log10(df[['k(cm^3/s)']].values)\n",
    "\n",
    "scalerx = MinMaxScaler()\n",
    "scalerx.fit(x)\n",
    "x_s = scalerx.transform(x)\n",
    "\n",
    "#print(x_s[:,0])\n",
    "#print(x[:,0])\n",
    "\n",
    "vmap_toreal = {}\n",
    "\n",
    "for i, vn in enumerate(x_s[:,0]):\n",
    "    vmap_toreal[vn] = x[i,0]\n",
    "\n",
    "print(\"V map: \")\n",
    "for a in vmap_toreal:\n",
    "    print(\"%4.2f --> %3d\"%(a, vmap_toreal[a]))\n",
    "\n",
    "vset = set(x_s[:,0])\n",
    "wset = set(x_s[:,1])\n",
    "tset = set(x_s[:,2])\n",
    "\n",
    "scalery = MinMaxScaler()\n",
    "scalery.fit(y)\n",
    "y_s = scalery.transform(y)\n",
    "\n",
    "if debug:\n",
    "    for i, ys in enumerate(y_s):\n",
    "        print(ys, y[i])\n",
    "    for i, xs in enumerate(x_s):\n",
    "        print(xs, x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.optimizers as tko\n",
    "import tensorflow.keras.activations as tka\n",
    "import tensorflow.keras.losses as tkl\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import commonmodules as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chek data\n",
    "#for w in wset:\n",
    "#    train_x, test_x, train_y, test_y = cm.test_train_split (1, [w], x_s, y_s)\n",
    "#\n",
    "#    cm.plotfull3dcurve (1, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofp = open(\"vremoved.csv\", \"w\")\n",
    "\n",
    "modelshape = [32, 32, 32, 32]\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "thefirst = True\n",
    "\n",
    "print (\" v Removed , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "print (\" v Removed , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp)\n",
    "for v in vset:\n",
    "    train_x, test_x, train_y, test_y = cm.test_train_split (0, [v], x_s, y_s)\n",
    "\n",
    "    if thefirst:\n",
    "        model = cm.buildmodel(modelshape)\n",
    "        history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "            verbose=0)\n",
    "        thefirst = False\n",
    "\n",
    "    model = cm.buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "    \n",
    "    ofptest = open(\"vremoved_\"+str(vmap_toreal[v])+\"_test.csv\", \"w\")\n",
    "    print (\" v , w , T , y , y_pred \", file=ofptest)\n",
    "    test_x_sp = scalerx.inverse_transform(test_x)\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    test_y_sb = scalery.inverse_transform(test_y)\n",
    "    for i, yt in enumerate(test_y_sb):\n",
    "         print (\" %3d , %3d , %6d , %10.8e , %10.8e  \"%(test_x_sp[i,0], \n",
    "                                             test_x_sp[i,1],\n",
    "                                             test_x_sp[i,2],\n",
    "                                             yt,\n",
    "                                             pred_y_sb[i]), file=ofptest, flush=True)\n",
    "    #plt.scatter(test_y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y_sb, pred_y_sb)\n",
    "    testr2 = metrics.r2_score(test_y_sb, pred_y_sb)\n",
    "    ofptest.close()\n",
    "\n",
    "    ofptrain = open(\"vremoved_\"+str(vmap_toreal[v])+\"_train.csv\", \"w\")\n",
    "    print (\" v , w , T , y , y_pred  \", file=ofptrain)\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    train_y_sb = scalery.inverse_transform(train_y)\n",
    "    train_x_sp = scalerx.inverse_transform(train_x)\n",
    "    for i, yt in enumerate(train_y_sb):\n",
    "         print (\" %3d , %3d , %6d , %10.8e , %10.8e  \"%(train_x_sp[i,0], \n",
    "                                             train_x_sp[i,1],\n",
    "                                             train_x_sp[i,2],\n",
    "                                             yt,\n",
    "                                             pred_y_sb[i]), file=ofptrain, flush=True)\n",
    "    #plt.scatter(train_y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    trainmse = metrics.mean_absolute_error(train_y_sb, pred_y_sb)\n",
    "    trainr2 = metrics.r2_score(train_y_sb, pred_y_sb)\n",
    "    ofptrain.close()\n",
    "    \n",
    "    print(\"%3d , %10.6e , %10.6f , %10.6e , %10.6f\"%(vmap_toreal[v], testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))\n",
    "    \n",
    "    print(\"%3d , %10.6e , %10.6f , %10.6e , %10.6f\"%(vmap_toreal[v], testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2), file=ofp)\n",
    "    \n",
    "ofp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlist = list(vset)\n",
    "\n",
    "vset_torm = []\n",
    "\n",
    "vtoremove = []\n",
    "for i in range(1,len(vlist),2):\n",
    "    vtoremove.append(vlist[i])\n",
    "vset_torm.append(vtoremove)\n",
    "\n",
    "vtoremove = []\n",
    "for i in range(0,len(vlist),2):\n",
    "    vtoremove.append(vlist[i])\n",
    "vset_torm.append(vtoremove)\n",
    "\n",
    "vtoremove = []\n",
    "for i in range(1,len(vlist),3):\n",
    "    vtoremove.append(vlist[i])\n",
    "    if (i+1 < len(vlist)):\n",
    "        vtoremove.append(vlist[i+1])\n",
    "vset_torm.append(vtoremove)\n",
    "\n",
    "vtoremove = []\n",
    "for i in range(0,len(vlist),3):\n",
    "    vtoremove.append(vlist[i])\n",
    "    if (i+1 < len(vlist)):\n",
    "        vtoremove.append(vlist[i+1])\n",
    "vset_torm.append(vtoremove)\n",
    "\n",
    "vtoremove = []\n",
    "for i in range(1,len(vlist),4):\n",
    "    vtoremove.append(vlist[i])\n",
    "    if (i+1 < len(vlist)):\n",
    "        vtoremove.append(vlist[i+1])\n",
    "    if (i+2 < len(vlist)):\n",
    "        vtoremove.append(vlist[i+2])\n",
    "vset_torm.append(vtoremove)\n",
    "\n",
    "vtoremove = []\n",
    "for i in range(0,len(vlist),4):\n",
    "    vtoremove.append(vlist[i])\n",
    "    if (i+1 < len(vlist)):\n",
    "        vtoremove.append(vlist[i+1])\n",
    "    if (i+2 < len(vlist)):\n",
    "        vtoremove.append(vlist[i+2])\n",
    "vset_torm.append(vtoremove)\n",
    "\n",
    "thefirst = True\n",
    "\n",
    "ofp = open(\"vsetremoved.csv\", \"w\")\n",
    "\n",
    "modelshape = [32, 32, 32, 32]\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "print (\" vset Removed , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "print (\" vset Removed , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp)\n",
    "for setid, v in enumerate(vset_torm):\n",
    "\n",
    "    train_x, test_x, train_y, test_y = cm.test_train_split (0, v, x_s, y_s)\n",
    "\n",
    "    v_sp = []\n",
    "    for val in v:\n",
    "        v_sp.append(vmap_toreal[val]) \n",
    "        \n",
    "    if thefirst:\n",
    "        model = cm.buildmodel(modelshape)\n",
    "        history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "            verbose=0)\n",
    "        thefirst = False\n",
    "\n",
    "    model = cm.buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    ofptest = open(\"vremoved_set\"+str(setid+1)+\"_test.csv\", \"w\")\n",
    "    print (\" v , w , T , y , y_pred\", file=ofptest)\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    test_x_sp = scalerx.inverse_transform(test_x)\n",
    "    pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    test_y_sb = scalery.inverse_transform(test_y)\n",
    "    for i, yt in enumerate(test_y_sb):\n",
    "        print (\" %3d , %3d , %6d , %10.8e , %10.8e  \"%(test_x_sp[i,0], \n",
    "                                             test_x_sp[i,1],\n",
    "                                             test_x_sp[i,2],\n",
    "                                             yt,\n",
    "                                             pred_y_sb[i]), file=ofptest, flush=True)\n",
    "    #plt.scatter(test_y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y_sb, pred_y_sb)\n",
    "    testr2 = metrics.r2_score(test_y_sb, pred_y_sb)\n",
    "    ofptest.close()\n",
    "\n",
    "    ofptrain = open(\"vremoved_set\"+str(setid+1)+\"_train.csv\", \"w\")\n",
    "    print (\" v , w , T , y , y_pred  \", file=ofptrain)\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    train_y_sb = scalery.inverse_transform(train_y)\n",
    "    train_x_sp = scalerx.inverse_transform(train_x)\n",
    "    for i, yt in enumerate(train_y_sb):\n",
    "         print (\" %3d , %3d , %6d , %10.8e , %10.8e  \"%(train_x_sp[i,0], \n",
    "                                             train_x_sp[i,1],\n",
    "                                             train_x_sp[i,2],\n",
    "                                             yt,\n",
    "                                             pred_y_sb[i]), file=ofptrain, flush=True)\n",
    "    #plt.scatter(train_y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    trainmse = metrics.mean_absolute_error(train_y_sb, pred_y_sb)\n",
    "    trainr2 = metrics.r2_score(train_y_sb, pred_y_sb)\n",
    "    ofptrain.close()\n",
    "        \n",
    "    print(\"%s , %10.6e , %10.6f , %10.6e , %10.6f\"%(v_sp, testmse, testr2, \\\n",
    "                                                        trainmse,  trainr2), flush=True)\n",
    "    print(\"%s , %10.6e , %10.6f , %10.6e , %10.6f\"%(v_sp, testmse, testr2, \\\n",
    "                                                        trainmse,  trainr2), file=ofp, flush=True)\n",
    "    \n",
    "ofp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "ofp = open(\"perc.csv\", \"w\")\n",
    "\n",
    "print (\" Perc. Split , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "print (\" Perc. Split , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp)\n",
    "for perc in [0.05, 0.10, 0.25, 0.30, 0.50]:\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x_s, y_s, \\\n",
    "                    test_size=perc, random_state=42)\n",
    "\n",
    "    modelshape = [64, 64, 64]\n",
    "    epochs = 20\n",
    "    batch_size = 50\n",
    "\n",
    "    model = cm.buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    #pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    #y_sb = scalery.inverse_transform(test_y)\n",
    "    #plt.scatter(y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(perc, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(perc, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2), file=ofp)\n",
    "    \n",
    "ofp.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ofp = open(\"wremoved.csv\", \"w\")\n",
    "\n",
    "thefirst = True\n",
    "\n",
    "print (\" w Removed , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "print (\" w Removed , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp)\n",
    "for w in wset:\n",
    "    train_x, test_x, train_y, test_y = cm.test_train_split (1, [w], x_s, y_s)\n",
    "\n",
    "    modelshape = [64, 64, 64]\n",
    "    epochs = 20\n",
    "    batch_size = 50\n",
    "\n",
    "    if thefirst:\n",
    "        model = cm.buildmodel(modelshape)\n",
    "        history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "            verbose=0)\n",
    "        thefirst = False\n",
    "\n",
    "    model = cm.buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    #pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    #y_sb = scalery.inverse_transform(test_y)\n",
    "    #plt.scatter(y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(w, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))\n",
    "    \n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(w, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2), file=ofp)\n",
    "    \n",
    "ofp.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ofp = open(\"tremoved.csv\", \"w\")\n",
    "\n",
    "thefirst = True\n",
    "\n",
    "print (\" T Removed , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "print (\" T Removed , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp)\n",
    "for t in tset:\n",
    "    train_x, test_x, train_y, test_y = cm.test_train_split (2, [t], x_s, y_s)\n",
    "\n",
    "    modelshape = [64, 64, 64]\n",
    "    epochs = 20\n",
    "    batch_size = 50\n",
    "\n",
    "    if thefirst:\n",
    "        model = cm.buildmodel(modelshape)\n",
    "        history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "            verbose=0)\n",
    "        thefirst = False\n",
    "\n",
    "    model = cm.buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    #pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    #y_sb = scalery.inverse_transform(test_y)\n",
    "    #plt.scatter(y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(t, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(t, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2), file=ofp)\n",
    "    \n",
    "ofp.close()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd7411e63421f098f1bf3ed11ee17c34ffcc3ddc87944e7f4685f5b8c2980583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
