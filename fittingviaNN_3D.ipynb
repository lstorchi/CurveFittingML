{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commonmodules as cm\n",
    "\n",
    "filename = \"N2H2_VVdata_3variables.xlsx\"\n",
    "df = pd.read_excel(filename)\n",
    "debug = False\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x = df[['v', 'w', 'T(K)']].values\n",
    "y = df[['k(cm^3/s)']].values\n",
    "\n",
    "scalerx = MinMaxScaler()\n",
    "scalerx.fit(x)\n",
    "x_s = scalerx.transform(x)\n",
    "\n",
    "vset = set(x_s[:,0])\n",
    "wset = set(x_s[:,1])\n",
    "tset = set(x_s[:,2])\n",
    "\n",
    "scalery = MinMaxScaler()\n",
    "scalery.fit(y)\n",
    "y_s = scalery.transform(y)\n",
    "\n",
    "if debug:\n",
    "    for i, ys in enumerate(y_s):\n",
    "        print(ys, y[i])\n",
    "    for i, xs in enumerate(x_s):\n",
    "        print(xs, x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.optimizers as tko\n",
    "import tensorflow.keras.activations as tka\n",
    "import tensorflow.keras.losses as tkl\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def test_train_split (column, valuestotest, x, y):\n",
    "    \n",
    "    xtest = []\n",
    "    ytest = []\n",
    "    xtrain = []\n",
    "    ytrain = []\n",
    "    \n",
    "    for v in valuestotest:\n",
    "        for i, xv in enumerate(x[:,column]):\n",
    "            if xv == v:\n",
    "                xtest.append(x[i,:])\n",
    "                ytest.append(y[i])\n",
    "            else:\n",
    "                xtrain.append(x[i,:])\n",
    "                ytrain.append(y[i])   \n",
    "\n",
    "    return np.asarray(xtrain), np.asarray(xtest), \\\n",
    "        np.asarray(ytrain), np.asarray(ytest)\n",
    "\n",
    "def buildmodel(modelshape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units = 3, activation = 'linear', input_shape=[3]))\n",
    "\n",
    "    for n in modelshape:\n",
    "        model.add(keras.layers.Dense(units = n, activation = 'relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(units = 1, activation = 'linear'))\n",
    "    model.compile(loss='mse', optimizer=\"adam\", metrics='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "def plotfull3dcurve (columntorm, x, y):\n",
    "\n",
    "    yv = []\n",
    "    xv = []\n",
    "    for i, v in enumerate(x):\n",
    "        toappend = []\n",
    "        for j in range(len(v)):\n",
    "            if j != columntorm:\n",
    "                toappend.append(v[j])\n",
    "        xv.append(toappend)\n",
    "        yv.append(y[i]) \n",
    "\n",
    "    X = np.array(xv)\n",
    "    Y = np.array(yv)\n",
    "\n",
    "    x1set = sorted(list(set(X[:,0])))\n",
    "    x2set = sorted(list(set(X[:,1])))\n",
    "\n",
    "    x1dim = len(x1set)\n",
    "    x2dim = len(x2set)\n",
    "\n",
    "    Xp = np.zeros((x1dim, x2dim), dtype=float)\n",
    "    Yp = np.zeros((x1dim, x2dim), dtype=float)\n",
    "    Zp = np.zeros((x1dim, x2dim), dtype=float)\n",
    "    for x1idx in range(x1dim):\n",
    "        x1 = x1set[x1idx]\n",
    "        for x2idx in range(x2dim):\n",
    "            x2 =  x2set[x2idx]\n",
    "            Xp[x1idx, x2idx] = float(x1)\n",
    "            Yp[x1idx, x2idx] = float(x2)\n",
    "\n",
    "            zval = None\n",
    "            for i in range(X.shape[0]):\n",
    "                if X[i,0] == x1 and X[i,1] == x2:\n",
    "                    zval = Y[i]\n",
    "                    break\n",
    "\n",
    "            Zp[x1idx, x2idx] = zval\n",
    "\n",
    "    #fig = plt.figure(figsize=(10,8))\n",
    "    fig = plt.figure(figsize=plt.figaspect(2.))\n",
    "    plt.gcf().set_size_inches(40, 30)\n",
    "    ax = fig.add_subplot(2,1,1, projection='3d')\n",
    "    surf = ax.plot_surface(Xp, Yp, Zp, rstride=1, cstride=1, cmap='jet', linewidth=0, antialiased=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chek data\n",
    "for w in wset:\n",
    "    train_x, test_x, train_y, test_y = test_train_split (1, [w], x_s, y_s)\n",
    "\n",
    "    plotfull3dcurve (1, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "ofp = open(\"perc.csv\", \"w\")\n",
    "\n",
    "print (\" Perc. Split , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "print (\" Perc. Split , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp)\n",
    "for perc in [0.05, 0.10, 0.25, 0.30, 0.50]:\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x_s, y_s, \\\n",
    "                    test_size=perc, random_state=42)\n",
    "\n",
    "    modelshape = [32, 32, 32, 32]\n",
    "    epochs = 10\n",
    "    batch_size = 50\n",
    "\n",
    "    model = buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    #pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    #y_sb = scalery.inverse_transform(test_y)\n",
    "    #plt.scatter(y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(perc, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(perc, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2), file=ofp)\n",
    "    \n",
    "ofp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofp = open(\"vremoved.csv\", \"w\")\n",
    "\n",
    "thefirst = True\n",
    "print (\" v Removed , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "print (\" v Removed , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp)\n",
    "for v in vset:\n",
    "    train_x, test_x, train_y, test_y = test_train_split (0, [v], x_s, y_s)\n",
    "\n",
    "    modelshape = [32, 32, 32, 32]\n",
    "    epochs = 10\n",
    "    batch_size = 50\n",
    "\n",
    "    if thefirst:\n",
    "        model = buildmodel(modelshape)\n",
    "        history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "            verbose=0)\n",
    "        thefirst = False\n",
    "\n",
    "    model = buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    #pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    #y_sb = scalery.inverse_transform(test_y)\n",
    "    #plt.scatter(y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(v, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))\n",
    "    \n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(v, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2), file=ofp)\n",
    "    \n",
    "ofp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofp = open(\"wremoved.csv\", \"w\")\n",
    "\n",
    "thefirst = True\n",
    "\n",
    "print (\" w Removed , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "print (\" w Removed , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp)\n",
    "for w in wset:\n",
    "    train_x, test_x, train_y, test_y = test_train_split (1, [w], x_s, y_s)\n",
    "\n",
    "    modelshape = [32, 32, 32, 32]\n",
    "    epochs = 10\n",
    "    batch_size = 50\n",
    "\n",
    "    if thefirst:\n",
    "        model = buildmodel(modelshape)\n",
    "        history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "            verbose=0)\n",
    "        thefirst = False\n",
    "\n",
    "    model = buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    #pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    #y_sb = scalery.inverse_transform(test_y)\n",
    "    #plt.scatter(y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(w, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))\n",
    "    \n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(w, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2), file=ofp)\n",
    "    \n",
    "ofp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofp = open(\"tremoved.csv\", \"w\")\n",
    "\n",
    "thefirst = True\n",
    "\n",
    "print (\" T Removed , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "print (\" T Removed , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp)\n",
    "for t in tset:\n",
    "    train_x, test_x, train_y, test_y = test_train_split (2, [t], x_s, y_s)\n",
    "\n",
    "    modelshape = [32, 32, 32, 32]\n",
    "    epochs = 10\n",
    "    batch_size = 50\n",
    "\n",
    "    if thefirst:\n",
    "        model = buildmodel(modelshape)\n",
    "        history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "            verbose=0)\n",
    "        thefirst = False\n",
    "\n",
    "    model = buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    #pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    #y_sb = scalery.inverse_transform(test_y)\n",
    "    #plt.scatter(y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(t, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(t, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2), file=ofp)\n",
    "    \n",
    "ofp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd7411e63421f098f1bf3ed11ee17c34ffcc3ddc87944e7f4685f5b8c2980583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
