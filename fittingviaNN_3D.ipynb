{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commonmodules as cm\n",
    "\n",
    "filename = \"N2H2_VVdata_3variables.xlsx\"\n",
    "df = pd.read_excel(filename)\n",
    "debug = False\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x = df[['v', 'w', 'T(K)']].values\n",
    "y = df[['k(cm^3/s)']].values\n",
    "\n",
    "scalerx = MinMaxScaler()\n",
    "scalerx.fit(x)\n",
    "x_s = scalerx.transform(x)\n",
    "\n",
    "vset = set(x_s[:,0])\n",
    "wset = set(x_s[:,1])\n",
    "tset = set(x_s[:,2])\n",
    "\n",
    "scalery = MinMaxScaler()\n",
    "scalery.fit(y)\n",
    "y_s = scalery.transform(y)\n",
    "\n",
    "if debug:\n",
    "    for i, ys in enumerate(y_s):\n",
    "        print(ys, y[i])\n",
    "    for i, xs in enumerate(x_s):\n",
    "        print(xs, x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.optimizers as tko\n",
    "import tensorflow.keras.activations as tka\n",
    "import tensorflow.keras.losses as tkl\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def test_train_split (column, valuestotest, x, y):\n",
    "    \n",
    "    xtest = []\n",
    "    ytest = []\n",
    "    xtrain = []\n",
    "    ytrain = []\n",
    "    \n",
    "    for v in valuestotest:\n",
    "        for i, xv in enumerate(x[:,column]):\n",
    "            if xv == v:\n",
    "                xtest.append(x[i,:])\n",
    "                ytest.append(y[i])\n",
    "            else:\n",
    "                xtrain.append(x[i,:])\n",
    "                ytrain.append(y[i])   \n",
    "\n",
    "    return np.asarray(xtrain), np.asarray(xtest), \\\n",
    "        np.asarray(ytrain), np.asarray(ytest)\n",
    "\n",
    "def buildmodel(modelshape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units = 3, activation = 'linear', input_shape=[3]))\n",
    "\n",
    "    for n in modelshape:\n",
    "        model.add(keras.layers.Dense(units = n, activation = 'relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(units = 1, activation = 'linear'))\n",
    "    model.compile(loss='mse', optimizer=\"adam\", metrics='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "def plotfull3dcurve (columntorm, x, y):\n",
    "\n",
    "    yv = []\n",
    "    xv = []\n",
    "    for i, v in enumerate(x):\n",
    "        xv.append()\n",
    "        yv.append() \n",
    "\n",
    "    X = np.array(xv)\n",
    "    Y = np.array(yv)\n",
    "\n",
    "    xdim = len(temp_values)\n",
    "    ydim = len(vib_values)\n",
    "\n",
    "    Xp = np.zeros((xdim, ydim), dtype=float)\n",
    "    Yp = np.zeros((xdim, ydim), dtype=float)\n",
    "    Zp = np.zeros((xdim, ydim), dtype=float)\n",
    "    for xidx in range(xdim):\n",
    "        t = temp_values[xidx]\n",
    "        for yidx in range(ydim):\n",
    "            v =  vib_values[yidx]\n",
    "            Xp[xidx, yidx] = float(t)\n",
    "            Yp[xidx, yidx] = float(v)\n",
    "            Zp[xidx, yidx] = df[t].values[yidx]\n",
    "\n",
    "    #fig = plt.figure(figsize=(10,8))\n",
    "    fig = plt.figure(figsize=plt.figaspect(2.))\n",
    "    plt.gcf().set_size_inches(40, 30)\n",
    "    ax = fig.add_subplot(2,1,1, projection='3d')\n",
    "    surf = ax.plot_surface(Xp, Yp, Zp, rstride=1, cstride=1, cmap='jet', linewidth=0, antialiased=False)\n",
    "    plt.show()\n",
    "def plot (x, y):\n",
    "\n",
    "  cm.plotfull3dcurve (df, vib_values, temp_values)\n",
    "\n",
    "  train_xy, train_z, test_xy, test_z = cm.get_train_and_test_rmv (temp_values, vib_values, \\\n",
    "    df, testsetvib)\n",
    "\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "  for i in range(train_z.shape[0]):\n",
    "    x = train_xy[i,0]\n",
    "    y = train_xy[i,1]\n",
    "    z = train_z[i]\n",
    "    ax.scatter(x, y, z, marker=\"o\", color=\"g\")\n",
    "\n",
    "  for i in range(test_z.shape[0]):\n",
    "    x = test_xy[i,0]\n",
    "    y = test_xy[i,1]\n",
    "    z = test_z[i]\n",
    "    ax.scatter(x, y, z, marker=\"o\", color=\"r\")\n",
    "\n",
    "  ax.set_xlabel('X Label')\n",
    "  ax.set_ylabel('Y Label')\n",
    "  ax.set_zlabel('Z Label')\n",
    "  plt.gcf().set_size_inches(20, 15)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chek data\n",
    "for w in wset:\n",
    "    train_x, test_x, train_y, test_y = test_train_split (1, [w], x_s, y_s)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print (\" Perc. Split , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "for perc in [0.05, 0.10, 0.25, 0.30, 0.50]:\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x_s, y_s, \\\n",
    "                    test_size=perc, random_state=42)\n",
    "\n",
    "    modelshape = [32, 32, 32, 32]\n",
    "    epochs = 10\n",
    "    batch_size = 50\n",
    "\n",
    "    model = buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    #pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    #y_sb = scalery.inverse_transform(test_y)\n",
    "    #plt.scatter(y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(perc, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\" v Removed , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "for v in vset:\n",
    "    train_x, test_x, train_y, test_y = test_train_split (0, [v], x_s, y_s)\n",
    "\n",
    "    modelshape = [32, 32, 32, 32]\n",
    "    epochs = 10\n",
    "    batch_size = 50\n",
    "\n",
    "    model = buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    #pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    #y_sb = scalery.inverse_transform(test_y)\n",
    "    #plt.scatter(y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(v, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\" w Removed , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "for w in wset:\n",
    "    train_x, test_x, train_y, test_y = test_train_split (1, [w], x_s, y_s)\n",
    "\n",
    "    modelshape = [32, 32, 32, 32]\n",
    "    epochs = 10\n",
    "    batch_size = 50\n",
    "\n",
    "    model = buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    y_sb = scalery.inverse_transform(test_y)\n",
    "    plt.scatter(y_sb, pred_y_sb)\n",
    "    plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(w, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\" T Removed , Test MSE , Test R2 , Train MSE , Train R2\")\n",
    "for t in tset:\n",
    "    train_x, test_x, train_y, test_y = test_train_split (2, [t], x_s, y_s)\n",
    "\n",
    "    modelshape = [32, 32, 32, 32]\n",
    "    epochs = 10\n",
    "    batch_size = 50\n",
    "\n",
    "    model = buildmodel(modelshape)\n",
    "    history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "        verbose=0)\n",
    "\n",
    "    pred_y = model.predict(test_x, verbose=0)\n",
    "    #to scale back y\n",
    "    #pred_y_sb = scalery.inverse_transform(pred_y)\n",
    "    #y_sb = scalery.inverse_transform(test_y)\n",
    "    #plt.scatter(y_sb, pred_y_sb)\n",
    "    #plt.show()\n",
    "    testmse = metrics.mean_absolute_error(test_y, pred_y)\n",
    "    testr2 = metrics.r2_score(test_y, pred_y)\n",
    "\n",
    "    pred_y = model.predict(train_x, verbose=0)\n",
    "    trainmse = metrics.mean_absolute_error(train_y, pred_y)\n",
    "    trainr2 = metrics.r2_score(train_y, pred_y)\n",
    "\n",
    "    print(\"%5.2f , %10.6f , %10.6f , %10.6f , %10.6f\"%(t, testmse, testr2, \\\n",
    "                                                       trainmse,  trainr2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd7411e63421f098f1bf3ed11ee17c34ffcc3ddc87944e7f4685f5b8c2980583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
