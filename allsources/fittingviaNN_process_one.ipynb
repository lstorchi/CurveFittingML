{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#import keras\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras.optimizers as tko\n",
    "import keras.activations as tka\n",
    "import keras.losses as tkl\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import commonmodules as cm\n",
    "\n",
    "#import fittingviaNN_3D_CLI as f3d\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fittingviaNN_process_one as f3d\n",
    "\n",
    "filename = \"N2H2_VV_process.xlsx\"\n",
    "testtovisualize = False\n",
    "wselected = 0\n",
    "columselected = 1\n",
    "\n",
    "df = pd.read_excel(filename)\n",
    "\n",
    "x = df[['v', 'w', 'T']].values\n",
    "y = df[['RC']].values\n",
    "usedlog10 = True\n",
    "if usedlog10:\n",
    "    y = np.log10(y)\n",
    "scalery = MinMaxScaler()\n",
    "scalery.fit(y)\n",
    "y_s = scalery.transform(y)\n",
    "\n",
    "scalerx = MinMaxScaler()\n",
    "scalerx.fit(x)\n",
    "x_s = scalerx.transform(x)\n",
    "\n",
    "vmap_toreal = {}\n",
    "\n",
    "for i, vn in enumerate(x_s[:,0]):\n",
    "    vmap_toreal[vn] = x[i,0]\n",
    "\n",
    "print(\"V map: \")\n",
    "for a in vmap_toreal:\n",
    "    print(\"%4.2f --> %3d\"%(a, vmap_toreal[a]))\n",
    "\n",
    "vset = set(x_s[:,0])\n",
    "wset = set(x_s[:,1])\n",
    "tset = set(x_s[:,2])\n",
    "vlist = list(vset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chek data\n",
    "#for w in wset:\n",
    "#    train_x, test_x, train_y, test_y = cm.test_train_split (1, [w], x_s, y_s)\n",
    "#\n",
    "#    cm.plotfull3dcurve (1, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so all the models should start from the same point\n",
    "#np.random.seed(812)\n",
    "#keras.utils.set_random_seed(812)\n",
    "#tf.config.experimental.enable_op_determinism()\n",
    "import time\n",
    "\n",
    "modelshape_s = [\n",
    "        [256, 256, 256], \n",
    "        [256, 256, 256, 256, 256, 256]]\n",
    "batch_size_s = [50, 256]\n",
    "epochs_s = [1000]\n",
    "lossfuns = ['mse']\n",
    "optimizers = ['adam']\n",
    "activations = ['relu']\n",
    "\n",
    "# run a grid search\n",
    "totalnum = len(modelshape_s)*\\\n",
    "        len(batch_size_s)*len(epochs_s)*\\\n",
    "            len(lossfuns)*len(optimizers)*len(activations)\n",
    "print(\"Total number of models to run: \", totalnum)\n",
    "modelnum = 0\n",
    "for modelshape in modelshape_s:\n",
    "    for batch_size in batch_size_s:\n",
    "        for epochs  in epochs_s:\n",
    "            for lossfun in lossfuns:\n",
    "                for optimizer in optimizers:\n",
    "                    for activation in activations:\n",
    "                        modelnum += 1\n",
    "\n",
    "                        r2test_v_split = 0.0\n",
    "                        msetest_v_split = 0.0\n",
    "                        r2train_v_split = 0.0 \n",
    "                        msetrain_v_split = 0.0\n",
    "                        \n",
    "                        r2test_vsets_split = 0.0\n",
    "                        msetest_vsets_split = 0.0\n",
    "                        r2train_vsets_split = 0.0 \n",
    "                        msetrain_vsets_split = 0.0\n",
    "\n",
    "                        timestart = time.time()\n",
    "\n",
    "                        r2train_v_split, msetrain_v_split, r2test_v_split, msetest_v_split = \\\n",
    "                            f3d.build_v_split (x_s, y_s, scalery, scalerx, False, vset, modelshape, \\\n",
    "                                        batch_size, epochs, \\\n",
    "                                        lossfun, optimizer, activation, \\\n",
    "                                        vmap_toreal, modelfname=\"vsplitmodel_\"+str(modelnum)+\".csv\")\n",
    "                        \n",
    "                        r2train_vsets_split, msetrain_vsets_split, \\\n",
    "                            r2test_vsets_split, msetest_vsets_split = \\\n",
    "                            f3d.build_vsets_split (x_s, y_s, scalery, scalerx, False, vlist, modelshape, \\\n",
    "                                            batch_size, epochs, \\\n",
    "                                            lossfun, optimizer, activation, \\\n",
    "                                            vmap_toreal, modelfname=\"vsetsplitmodel_\"+str(modelnum)+\".csv\")\n",
    "                        \n",
    "                        print(\"v split , Model metrics %3d , %10.5f , %10.5f , %10.5f , %10.5f\"%( \\\n",
    "                            modelnum, r2test_v_split, msetest_v_split, \\\n",
    "                            r2train_v_split, msetrain_v_split), flush=True)\n",
    "                        print(\"vsets split , Model metrics %3d , %10.5f , %10.5f , %10.5f , %10.5f\"%( \\\n",
    "                            modelnum, r2test_vsets_split, msetest_vsets_split, \\\n",
    "                            r2train_vsets_split, msetrain_vsets_split), flush=True)\n",
    "                        print(\"Model shapes  %3d , %s , %5d , %5d , %s , %s , %s \"%( \\\n",
    "                             modelnum, str(modelshape), batch_size, epochs, \\\n",
    "                                lossfun, optimizer, activation), flush=True)\n",
    "                        \n",
    "                        timeend = time.time()\n",
    "                        print(\"Total seconds taken: \", timeend-timestart, flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasttf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
