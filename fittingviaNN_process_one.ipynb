{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.optimizers as tko\n",
    "import tensorflow.keras.activations as tka\n",
    "import tensorflow.keras.losses as tkl\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import commonmodules as cm\n",
    "\n",
    "#import fittingviaNN_3D_CLI as f3d\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "\n",
    "class SaveModelEpoch(keras.callbacks.Callback):\n",
    "    def __init__(self, filepath):\n",
    "        super(SaveModelEpoch, self).__init__()\n",
    "        self.filepath = filepath\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_str = '{:04d}'.format(epoch + 1)  # Format epoch number\n",
    "        filepath = self.filepath.format(epoch=epoch_str)\n",
    "        self.model.save(filepath)\n",
    "        #print(f\"\\nSaved model at epoch {epoch + 1} to {filepath}\")\n",
    "    \n",
    "#######################################################################\n",
    "\n",
    "def build_v_split (x_s, y_s, scalery, alsolog10, vset, modelshape, batch_size, epochs, \\\n",
    "                lossfun, optimizer, activation, \\\n",
    "                vmap_toreal, modelfname=\"\", verbose=False):\n",
    "\n",
    "    ofp = None\n",
    "    if modelfname != \"\":\n",
    "        ofp = open(modelfname, \"w\")\n",
    "\n",
    "    avgr2_test = 0.0\n",
    "    avgr2_train = 0.0\n",
    "    avgmse_test = 0.0\n",
    "    avgmse_train = 0.0\n",
    "\n",
    "    num = 0.0\n",
    "    basename = \"\" \n",
    "    if modelfname != \"\":\n",
    "        basename = modelfname.split(\".csv\")[0]\n",
    "\n",
    "    #early_stopping = keras.callbacks.EarlyStopping(\n",
    "    #    monitor='mse',\n",
    "    #    patience=10,\n",
    "    #    min_delta=0.00001,\n",
    "    #    mode='min',\n",
    "    #    verbose=1\n",
    "    #)\n",
    "\n",
    "    if verbose:\n",
    "        print (\" v Removed , Test MSE , Test R2 , Train MSE , Train R2\", flush=True)\n",
    "    if modelfname != \"\":\n",
    "        print (\" v Removed , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp, flush=True)\n",
    "    for v in vset:\n",
    "        train_x, test_x, train_y, test_y = cm.test_train_split (0, [v], x_s, y_s)\n",
    "\n",
    "        model = cm.buildmodel(modelshape, lossf=lossfun, optimizerf=optimizer, \\\n",
    "                                    activationf=activation)\n",
    "        \n",
    "        filepath = 'model_epoch_{epoch}.keras' \n",
    "        save_model_callback = SaveModelEpoch(filepath)\n",
    "\n",
    "        history = model.fit(train_x, train_y, \\\n",
    "                            epochs=epochs,  \\\n",
    "                            batch_size=batch_size, \\\n",
    "                            callbacks=[save_model_callback], \\\n",
    "                            verbose=0)\n",
    "        # plot training history\n",
    "        #plt.plot(history.history[lossfun], label='train')   \n",
    "        #plt.legend()\n",
    "        #plt.show()\n",
    "        # print the min of the training loss and epoch\n",
    "        minmse = min(history.history[lossfun])\n",
    "        minepoch = np.argmin(history.history[lossfun])\n",
    "        print(\"Test v: \", vmap_toreal[v])\n",
    "        print(\"  min training loss: \", minmse)\n",
    "        print(\"  epoch of min training loss: \", minepoch)\n",
    "        epoch_str = '{:04d}'.format(minepoch + 1)  # Format epoch number\n",
    "        filename = filepath.format(epoch=epoch_str)\n",
    "        # load the model with the min training loss\n",
    "        model = keras.models.load_model(filename)\n",
    "        # remove all the files\n",
    "        for i in range(epochs):\n",
    "            try:\n",
    "                epoch_str = '{:04d}'.format(i + 1)  # Format epoch number\n",
    "                filename = filepath.format(epoch=epoch_str)\n",
    "                os.remove(filename)\n",
    "            except:\n",
    "                print(\"error in removing file: \", filepath.format(epoch=i)) \n",
    "            \n",
    "        pred_y = model.predict(test_x, verbose=0)\n",
    "        original_test_y = scalery.inverse_transform(test_y)\n",
    "        original_pred_y = scalery.inverse_transform(pred_y)\n",
    "        if alsolog10:\n",
    "            original_test_y = 10**original_test_y\n",
    "            original_pred_y = 10**original_pred_y\n",
    "        testfile = basename + \"_\" + str(vmap_toreal[v]) + \"_test.csv\"\n",
    "        with open(testfile, \"a\") as f:\n",
    "            for ix, xval in enumerate(test_x):\n",
    "                for xx in xval:\n",
    "                    print(\"%10.5e, \"%xx, end=\"\", file=f)\n",
    "                print(\"%10.5e\"%(original_pred_y[ix]), file=f)\n",
    "        try:\n",
    "            testmse = metrics.mean_absolute_error(original_test_y, original_pred_y)\n",
    "            testr2 = metrics.r2_score(original_test_y, original_pred_y)\n",
    "        except:\n",
    "            testmse = float('inf')\n",
    "            testr2 = 0.0\n",
    "\n",
    "        avgr2_test += testr2\n",
    "        avgmse_test += testmse\n",
    "\n",
    "        pred_y = model.predict(train_x, verbose=0)\n",
    "        original_train_y = scalery.inverse_transform(train_y)\n",
    "        original_pred_y = scalery.inverse_transform(pred_y)\n",
    "        if alsolog10:\n",
    "            original_train_y = 10**original_train_y\n",
    "            original_pred_y = 10**original_pred_y\n",
    "        trainfile = basename + \"_\" + str(vmap_toreal[v]) + \"_train.csv\"\n",
    "        with open(trainfile, \"a\") as f:\n",
    "            for ix, xval in enumerate(train_x):\n",
    "                for xx in xval:\n",
    "                    print(\"%10.5e, \"%xx, end=\"\", file=f)\n",
    "                print(\"%10.5e\"%(original_pred_y[ix]), file=f)\n",
    "        try:\n",
    "            trainmse = metrics.mean_absolute_error(original_train_y, original_pred_y)\n",
    "            trainr2 = metrics.r2_score(original_train_y, original_pred_y)\n",
    "        except:\n",
    "            trainmse = float('inf')\n",
    "            trainr2 = 0.0\n",
    "\n",
    "        avgr2_train += trainr2\n",
    "        avgmse_train += trainmse\n",
    "\n",
    "        num += 1.0\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"%5d , %10.6f , %10.6f , %10.6f , %10.6f\"%(vmap_toreal[v], testmse, testr2, \\\n",
    "                                                        trainmse,  trainr2), flush=True)\n",
    "        \n",
    "        if modelfname != \"\":\n",
    "            print(\"%5d , %10.6f , %10.6f , %10.6f , %10.6f\"%(vmap_toreal[v], testmse, testr2, \\\n",
    "                                                        trainmse,  trainr2), file=ofp, flush=True)\n",
    "    \n",
    "    if modelfname != \"\":\n",
    "        ofp.close()\n",
    "\n",
    "    return avgr2_train/num, avgmse_train/num, avgr2_test/num, avgmse_test/num\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "def build_vsets_split (x_s, y_s, scalery, alsolog10, vlist, modelshape, batch_size, epochs, \\\n",
    "                    lossfun, optimizer, activation, \\\n",
    "                    vmap_toreal, modelfname=\"\", verbose=False):\n",
    "\n",
    "    ofp = None\n",
    "    if modelfname != \"\":\n",
    "        ofp = open(modelfname, \"w\")\n",
    "\n",
    "    basename = \"\" \n",
    "    if modelfname != \"\":\n",
    "        basename = modelfname.split(\".csv\")[0]\n",
    "\n",
    "    avgr2_test = 0.0\n",
    "    avgr2_train = 0.0\n",
    "    avgmse_test = 0.0\n",
    "    avgmse_train = 0.0\n",
    "\n",
    "    num = 0.0\n",
    "\n",
    "    thefirst = True\n",
    "    if verbose:\n",
    "        print (\" vset Removed , Test MSE , Test R2 , Train MSE , Train R2\", flush=True)\n",
    "    if modelfname != \"\":\n",
    "        print (\" vset Removed , Test MSE , Test R2 , Train MSE , Train R2\", file=ofp, flush=True)\n",
    "\n",
    "    vset_torm = []\n",
    "\n",
    "    vtoremove = []\n",
    "    for i in range(1,len(vlist),2):\n",
    "        vtoremove.append(vlist[i])\n",
    "    vset_torm.append(vtoremove)\n",
    "\n",
    "    vtoremove = []\n",
    "    for i in range(0,len(vlist),2):\n",
    "        vtoremove.append(vlist[i])\n",
    "    vset_torm.append(vtoremove)\n",
    "\n",
    "    vtoremove = []\n",
    "    for i in range(1,len(vlist),3):\n",
    "        vtoremove.append(vlist[i])\n",
    "        if (i+1 < len(vlist)):\n",
    "            vtoremove.append(vlist[i+1])\n",
    "    vset_torm.append(vtoremove)\n",
    "\n",
    "    vtoremove = []\n",
    "    for i in range(0,len(vlist),3):\n",
    "        vtoremove.append(vlist[i])\n",
    "        if (i+1 < len(vlist)):\n",
    "            vtoremove.append(vlist[i+1])\n",
    "    vset_torm.append(vtoremove)\n",
    "\n",
    "    vtoremove = []\n",
    "    for i in range(1,len(vlist),4):\n",
    "        vtoremove.append(vlist[i])\n",
    "        if (i+1 < len(vlist)):\n",
    "            vtoremove.append(vlist[i+1])\n",
    "        if (i+2 < len(vlist)):\n",
    "            vtoremove.append(vlist[i+2])\n",
    "    vset_torm.append(vtoremove)\n",
    "\n",
    "    vtoremove = []\n",
    "    for i in range(0,len(vlist),4):\n",
    "        vtoremove.append(vlist[i])\n",
    "        if (i+1 < len(vlist)):\n",
    "            vtoremove.append(vlist[i+1])\n",
    "        if (i+2 < len(vlist)):\n",
    "            vtoremove.append(vlist[i+2])\n",
    "    vset_torm.append(vtoremove)\n",
    "\n",
    "    #print(len(vlist))\n",
    "    #for v in vset_torm:\n",
    "    #    print(len(v), v)\n",
    "\n",
    "    for v in vset_torm:\n",
    "\n",
    "        train_x, test_x, train_y, test_y = cm.test_train_split (0, v, x_s, y_s)\n",
    "\n",
    "        if thefirst:\n",
    "            model = cm.buildmodel(modelshape, lossf=lossfun, optimizerf=optimizer, \\\n",
    "                                    activationf=activation)\n",
    "            history = model.fit(train_x, train_y, epochs=10,  batch_size=batch_size, \\\n",
    "                verbose=0)\n",
    "            thefirst = False\n",
    "\n",
    "        model = cm.buildmodel(modelshape, lossf=lossfun, optimizerf=optimizer, \\\n",
    "                                    activationf=activation)\n",
    "        history = model.fit(train_x, train_y, epochs=epochs,  batch_size=batch_size, \\\n",
    "            verbose=0)\n",
    "        valuetoprint = \"\"\n",
    "        for val in v:\n",
    "            valuetoprint += str(vmap_toreal[val]) + \"_\"\n",
    "        #plt.plot(history.history[lossfun], label='train')\n",
    "        #plt.legend()\n",
    "        #plt.show()\n",
    "        print(\"Test Vset: \", valuetoprint)\n",
    "        print(\"  min training loss: \", min(history.history[lossfun]))\n",
    "        print(\"  epoch of min training loss: \", np.argmin(history.history[lossfun]))\n",
    "\n",
    "        pred_y = model.predict(test_x, verbose=0)\n",
    "        original_test_y = scalery.inverse_transform(test_y)\n",
    "        original_pred_y = scalery.inverse_transform(pred_y)\n",
    "        if alsolog10:\n",
    "            original_test_y = 10**original_test_y\n",
    "            original_pred_y = 10**original_pred_y\n",
    "        try:\n",
    "            testmse = metrics.mean_absolute_error(original_test_y, original_pred_y)\n",
    "            testr2 = metrics.r2_score(original_test_y, original_pred_y)\n",
    "        except:\n",
    "            testmse = float('inf')\n",
    "            testr2 = 0.0\n",
    "\n",
    "        avgr2_test += testr2\n",
    "        avgmse_test += testmse\n",
    "\n",
    "        pred_y = model.predict(train_x, verbose=0)\n",
    "        original_train_y = scalery.inverse_transform(train_y)\n",
    "        original_pred_y = scalery.inverse_transform(pred_y)\n",
    "        if alsolog10:\n",
    "            original_train_y = 10**original_train_y\n",
    "            original_pred_y = 10**original_pred_y\n",
    "        try:\n",
    "            trainmse = metrics.mean_absolute_error(original_train_y, original_pred_y)\n",
    "            trainr2 = metrics.r2_score(original_train_y, original_pred_y)\n",
    "        except:\n",
    "            trainmse = float('inf')\n",
    "            trainr2 = 0.0\n",
    "\n",
    "        avgr2_train += trainr2\n",
    "        avgmse_train += trainmse\n",
    "\n",
    "        num += 1.0\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"%s , %10.6f , %10.6f , %10.6f , %10.6f\"%(valuetoprint, testmse, testr2, \\\n",
    "                                                        trainmse,  trainr2), flush=True)\n",
    "        if modelfname != \"\":\n",
    "            print(\"%s , %10.6f , %10.6f , %10.6f , %10.6f\"%(valuetoprint, testmse, testr2, \\\n",
    "                                                        trainmse,  trainr2), file=ofp, flush=True)\n",
    "    \n",
    "    if modelfname != \"\":\n",
    "        ofp.close()\n",
    "\n",
    "\n",
    "    return avgr2_train/num, avgmse_train/num, avgr2_test/num, avgmse_test/num\n",
    "\n",
    "#######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"N2H2_VV_process.xlsx\"\n",
    "testtovisualize = False\n",
    "wselected = 0\n",
    "columselected = 1\n",
    "\n",
    "df = pd.read_excel(filename)\n",
    "\n",
    "x = df[['v', 'w', 'T']].values\n",
    "y = df[['RC']].values\n",
    "usedlog10 = True\n",
    "if usedlog10:\n",
    "    y = np.log10(y)\n",
    "scalery = MinMaxScaler()\n",
    "scalery.fit(y)\n",
    "y_s = scalery.transform(y)\n",
    "\n",
    "scalerx = MinMaxScaler()\n",
    "scalerx.fit(x)\n",
    "x_s = scalerx.transform(x)\n",
    "\n",
    "vmap_toreal = {}\n",
    "\n",
    "for i, vn in enumerate(x_s[:,0]):\n",
    "    vmap_toreal[vn] = x[i,0]\n",
    "\n",
    "print(\"V map: \")\n",
    "for a in vmap_toreal:\n",
    "    print(\"%4.2f --> %3d\"%(a, vmap_toreal[a]))\n",
    "\n",
    "vset = set(x_s[:,0])\n",
    "wset = set(x_s[:,1])\n",
    "tset = set(x_s[:,2])\n",
    "vlist = list(vset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chek data\n",
    "#for w in wset:\n",
    "#    train_x, test_x, train_y, test_y = cm.test_train_split (1, [w], x_s, y_s)\n",
    "#\n",
    "#    cm.plotfull3dcurve (1, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so all the models should start from the same point\n",
    "#np.random.seed(812)\n",
    "#keras.utils.set_random_seed(812)\n",
    "#tf.config.experimental.enable_op_determinism()\n",
    "import time\n",
    "\n",
    "modelshape_s = [\n",
    "        [256, 256, 256]]\n",
    "batch_size_s = [256]\n",
    "epochs_s = [1000]\n",
    "lossfuns = ['mse']\n",
    "optimizers = ['adam']\n",
    "activations = ['relu']\n",
    "\n",
    "# run a grid search\n",
    "totalnum = len(modelshape_s)*\\\n",
    "        len(batch_size_s)*len(epochs_s)*\\\n",
    "            len(lossfuns)*len(optimizers)*len(activations)\n",
    "print(\"Total number of models to run: \", totalnum)\n",
    "modelnum = 0\n",
    "for modelshape in modelshape_s:\n",
    "    for batch_size in batch_size_s:\n",
    "        for epochs  in epochs_s:\n",
    "            for lossfun in lossfuns:\n",
    "                for optimizer in optimizers:\n",
    "                    for activation in activations:\n",
    "                        modelnum += 1\n",
    "\n",
    "                        r2test_v_split = 0.0\n",
    "                        msetest_v_split = 0.0\n",
    "                        r2train_v_split = 0.0 \n",
    "                        msetrain_v_split = 0.0\n",
    "                        \n",
    "                        r2test_vsets_split = 0.0\n",
    "                        msetest_vsets_split = 0.0\n",
    "                        r2train_vsets_split = 0.0 \n",
    "                        msetrain_vsets_split = 0.0\n",
    "\n",
    "                        timestart = time.time()\n",
    "\n",
    "                        r2train_v_split, msetrain_v_split, r2test_v_split, msetest_v_split = \\\n",
    "                            build_v_split (x_s, y_s, scalery, False, vset, modelshape, \\\n",
    "                                        batch_size, epochs, \\\n",
    "                                        lossfun, optimizer, activation, \\\n",
    "                                        vmap_toreal, modelfname=\"vsplitmodel_\"+str(modelnum)+\".csv\")\n",
    "                        \n",
    "                        r2train_vsets_split, msetrain_vsets_split, \\\n",
    "                            r2test_vsets_split, msetest_vsets_split = \\\n",
    "                            build_vsets_split (x_s, y_s, scalery, False, vlist, modelshape, \\\n",
    "                                            batch_size, epochs, \\\n",
    "                                            lossfun, optimizer, activation, \\\n",
    "                                            vmap_toreal, modelfname=\"vsetsplitmodel_\"+str(modelnum)+\".csv\")\n",
    "                        \n",
    "                        print(\"v split , Model metrics %3d , %10.5f , %10.5f , %10.5f , %10.5f\"%( \\\n",
    "                            modelnum, r2test_v_split, msetest_v_split, \\\n",
    "                            r2train_v_split, msetrain_v_split), flush=True)\n",
    "                        print(\"vsets split , Model metrics %3d , %10.5f , %10.5f , %10.5f , %10.5f\"%( \\\n",
    "                            modelnum, r2test_vsets_split, msetest_vsets_split, \\\n",
    "                            r2train_vsets_split, msetrain_vsets_split), flush=True)\n",
    "                        print(\"Model shapes  %3d , %s , %5d , %5d , %s , %s , %s \"%( \\\n",
    "                             modelnum, str(modelshape), batch_size, epochs, \\\n",
    "                                lossfun, optimizer, activation), flush=True)\n",
    "                        \n",
    "                        timeend = time.time()\n",
    "                        print(\"Total seconds taken: \", timeend-timestart, flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd7411e63421f098f1bf3ed11ee17c34ffcc3ddc87944e7f4685f5b8c2980583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
